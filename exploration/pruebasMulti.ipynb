{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8811143",
   "metadata": {},
   "source": [
    "# Estructura de agentes\n",
    "- Supervisor\n",
    "    - Agente Rag\n",
    "    - Agente WebSearch\n",
    "    - agemte respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cdb4448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langgraph.graph import Graph\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_ollama import OllamaLLM\n",
    "from typing import Dict, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c62b4c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_question(state):\n",
    "    llm = OllamaLLM(\n",
    "        model=\"qwen2.5\",\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        num_gpu_layers=90,\n",
    "        num_ctx=1536,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "    Eres un agente que tiene que determinar si la pregunta que realiza el usuario es una recomendacion de libros o de peliculas. \n",
    "\n",
    "    Pregunta : {input}\n",
    "\n",
    "    Analiza la pregunta. Solo responde con \"libro\" si quiere un libro, o \"pelicula\" si quiere una pelicula. Si no es ninguna de las dos, responde \"ninguna\".\n",
    "\n",
    "    No des explicaciones ni detalles. Solo responde con una de las tres opciones.\n",
    "    \"\"\")\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"input\": state[\"input\"]})\n",
    "\n",
    "    # Retorna con las 3 claves para que el estado sea válido\n",
    "    return {\n",
    "        \"input\": state[\"input\"],\n",
    "        \"decision\": response,\n",
    "        \"output\": \"\"  # puedes poner \"\" o lo que quieras aquí\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d8d69c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pelicula\n"
     ]
    }
   ],
   "source": [
    "resultado = analyze_question({\"input\": \"quiero una pelicula que sea similar a star wars\"})\n",
    "print (resultado[\"decision\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aeb037b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.llms import Ollama\n",
    "from langchain_ollama import OllamaLLM\n",
    "from langchain.schema import Document\n",
    "import numpy as np\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3088f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palom\\AppData\\Local\\Temp\\ipykernel_19472\\2110578743.py:16: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "c:\\Users\\palom\\.conda\\envs\\UNIR_Practicas\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# === Datos de ejemplo ===\n",
    "libros = [\n",
    "    {\"titulo\": \"1984\", \"descripcion\": \"Una novela distópica sobre un régimen totalitario que lo vigila todo.\"},\n",
    "    {\"titulo\": \"El nombre del viento\", \"descripcion\": \"Historia de Kvothe, un joven con un talento excepcional para la magia y la música.\"},\n",
    "    {\"titulo\": \"Dune\", \"descripcion\": \"Una epopeya de ciencia ficción sobre poder, religión y ecología en un planeta desértico.\"},\n",
    "    {\"titulo\": \"Un mundo feliz\", \"descripcion\": \"Sociedad futurista donde la estabilidad se consigue a costa de la libertad individual.\"},\n",
    "]\n",
    "\n",
    "# Crear documentos\n",
    "documentos = [\n",
    "    Document(page_content=libro[\"descripcion\"], metadata={\"titulo\": libro[\"titulo\"]})\n",
    "    for libro in libros\n",
    "]\n",
    "\n",
    "# Embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Vectorstore FAISS\n",
    "vectorstore = FAISS.from_documents(documentos, embedding=embeddings)\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retrieverlibros = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "850c68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Datos de ejemplo ===\n",
    "movies = [\n",
    "    {\"titulo\": \"Inception\", \"descripcion\": \"Un ladrón con la habilidad de entrar en los sueños de las personas se enfrenta a su mayor desafío: implantar una idea en lugar de robarla.\"},\n",
    "    {\"titulo\": \"Interstellar\", \"descripcion\": \"Un grupo de astronautas viaja a través de un agujero de gusano en busca de un nuevo hogar para la humanidad.\"},\n",
    "    {\"titulo\": \"The Matrix\", \"descripcion\": \"Un programador descubre que la realidad es una simulación creada por máquinas y se une a una rebelión contra ellas.\"},\n",
    "    {\"titulo\": \"Blade Runner\", \"descripcion\": \"En un futuro distópico, un cazador de replicantes debe eliminar a androides que se han rebelado.\"},\n",
    "    {\"titulo\": \"Dune\", \"descripcion\": \"Un joven noble lidera a una tribu en un planeta desértico para reclamar su destino y proteger un recurso vital.\"}\n",
    "]\n",
    "\n",
    "\n",
    "# Crear documentos\n",
    "documentos = [\n",
    "    Document(page_content=movie[\"descripcion\"], metadata={\"titulo\": movie[\"titulo\"]})\n",
    "    for movie in movies\n",
    "]\n",
    "\n",
    "# Embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Vectorstore FAISS\n",
    "vectorstore = FAISS.from_documents(documentos, embedding=embeddings)\n",
    "\n",
    "# Retrieve and generate using the relevant snippets of the blog.\n",
    "retrievermovies= vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf7d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def libros_agent(state):\n",
    "    llm = OllamaLLM(\n",
    "        model=\"qwen2.5\",\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        num_gpu_layers=90,\n",
    "        num_ctx=1536,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\" Eres un bibliotecario experto en recomendar libros a los usuarios basandote en sus preferencias.\n",
    "            Tienes que dar una recomendación basandote en el input que recibas del usuario (recibiras un libro) que te diga el usuario \n",
    "            y teniendo en cuenta el contexto que tienes con la información de libros.\n",
    "            \n",
    "            Contexto: {context}\n",
    "                                            \n",
    "    \n",
    "            Pregunta del usuario: {input}\n",
    "                                                   \n",
    "            Genera la recomendación utilizando la siguiente estructura\n",
    "            📚 Libro recomendado: [Título exacto del libro]\n",
    "            ✍️ Autor: [Nombre del autor]\n",
    "            📅 Año de publicación: [Año]\n",
    "            🌟 Puntuación: [X.X/5] (si disponible)   \n",
    "                                                \n",
    "            Justifica la recomendación con un breve parrafo. No te extiendas mas de 3 lineas.\n",
    "\n",
    "            Justificación: [2-3 frases sobre similitudes con el libro de referencia]\n",
    "\n",
    "            Reglas:\n",
    "            1. Usa SOLO información de los libros proporcionados.\n",
    "            2. Si no hay libros similares, di: \"No encontré coincidencias precisas\".\n",
    "            3. Mantén la respuesta concisa y profesional.\n",
    "                                         \n",
    "        \"\"\"\n",
    "    )\n",
    "    rag_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"input\") | retrieverlibros,\n",
    "        \"input\": itemgetter(\"input\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "    response = rag_chain.invoke({\"input\": state[\"input\"]})\n",
    "    return {\"output\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3c4f6458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Libro recomendado: Dune  \n",
      "✍️ Autor: Frank Herbert  \n",
      "📅 Año de publicación: 1965  \n",
      "🌟 Puntuación: No disponible  \n",
      "\n",
      "Justificación: \"Dune\" comparte con Star Wars elementos de narrativa épica, exploraciones filosóficas y un mundo futurista rico en detalles, aunque se centra más en temas de poder, religión y ecología.\n"
     ]
    }
   ],
   "source": [
    "resultado = libros_agent({\"input\": \"quiero una libro que sea similar a star wars\"})\n",
    "print (resultado[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75d93adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pelis_agent(state):\n",
    "    llm = OllamaLLM(\n",
    "        model=\"qwen2.5\",\n",
    "        base_url=\"http://localhost:11434\",\n",
    "        num_gpu_layers=90,\n",
    "        num_ctx=1536,\n",
    "        temperature=0.5,\n",
    "    )\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\" Eres un critico de cine experto en recomendar libros a los usuarios basandote en sus preferencias.\n",
    "            Tienes que dar una recomendación basandote en el input que recibas del usuario (recibiras un libro) que te diga el usuario \n",
    "            y teniendo en cuenta el contexto que tienes con la información de libros.\n",
    "            \n",
    "             \n",
    "            Contexto: {context}\n",
    "                                            \n",
    "    \n",
    "            Pregunta del usuario: {input}\n",
    "                                                   \n",
    "            Genera la recomendación utilizando la siguiente estructura\n",
    "            \n",
    "            📚 Pelicula recomendado: [Título exacto del libro]\n",
    "            ✍️ Autor: [Nombre del autor] (si disponible) \n",
    "            📅 Año de publicación: [Año] (si disponible) \n",
    "            🌟 Puntuación: [X.X/5] (si disponible)   \n",
    "\n",
    "\n",
    "            Justifica la recomendación con un breve parrafo. No te extiendas mas de 3 lineas.\n",
    "\n",
    "            Justificación: [2-3 frases sobre similitudes con el libro de referencia]\n",
    "\n",
    "            Reglas:\n",
    "            1. Usa SOLO información de las peliculas proporcionados.\n",
    "            2. Si no hay libros similares, di: \"No encontré coincidencias precisas\".\n",
    "            3. Mantén la respuesta concisa y profesional.\n",
    "        \n",
    "        \"\"\"\n",
    "    )\n",
    "    rag_chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"input\") | retrievermovies,\n",
    "        \"input\": itemgetter(\"input\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "    response = rag_chain.invoke({\"input\": state[\"input\"]})\n",
    "    return {\"output\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea317eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agente general\n",
    "def general_agent(state):\n",
    "    llm = OllamaLLM(\n",
    "    model=\"qwen2.5\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    num_gpu_layers=90,       # Aceleración Metal máxima\n",
    "    num_ctx=1536,            # Balance memoria/contexto\n",
    "    temperature=0.5,\n",
    "    )\n",
    "\n",
    "    prompt = PromptTemplate.from_template(\n",
    "        \"\"\"Da una respuesta breve y concisa a la siguiente pregunta: {input}\n",
    "\n",
    "        Si no sabes la respuesta di: \"Con mis conocimientos no te puedo dar una respuesta a tu pregunta\"\n",
    "\n",
    "        \"\"\"\n",
    "    )\n",
    "    chain = prompt | llm\n",
    "    response = chain.invoke({\"input\": state[\"input\"]})\n",
    "    return {\"output\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a091eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "#You can precise the format here which could be helpfull for multimodal graphs\n",
    "class AgentState(TypedDict):\n",
    "    input: str\n",
    "    output: str\n",
    "    decision: str\n",
    "def create_graph():    \n",
    "    workflow = StateGraph(AgentState)\n",
    "\n",
    "    workflow.add_node(\"analyze\", analyze_question)\n",
    "    workflow.add_node(\"libros_agent\", libros_agent)\n",
    "    workflow.add_node(\"pelis_agent\", pelis_agent)\n",
    "    workflow.add_node(\"general_agent\", general_agent)\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        \"analyze\",\n",
    "        lambda x: x[\"decision\"],\n",
    "        {\n",
    "            \"libro\": \"libros_agent\",\n",
    "            \"pelicula\": \"pelis_agent\",\n",
    "            \"ninguna\": \"general_agent\"\n",
    "        }\n",
    "    )\n",
    "\n",
    "    workflow.set_entry_point(\"analyze\")\n",
    "    workflow.add_edge(\"general_agent\", END)\n",
    "    workflow.add_edge(\"libros_agent\", END)\n",
    "    workflow.add_edge(\"pelis_agent\", END)\n",
    "\n",
    "    return workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "728148cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crea el grafo\n",
    "app = create_graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f21a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendacion:\n",
      "📚 Pelicula recomendada: Blade Runner\n",
      "🌟 Puntuación: No disponible\n",
      "\n",
      "Justificación: Blade Runner comparte con Star Wars una atmósfera futurista y un tono más sombrío, además de explorar temas como la identidad y el control tecnológico.\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 1: Pelicula\n",
    "input_data = {\n",
    "    \"input\": \"Quiero un libro que sea similar a Star Wars\",\n",
    "    \"output\": \"\",\n",
    "    \"decision\": \"\"   # Esta la llenará la función analyze_question\n",
    "}\n",
    "result1 = app.invoke({\"input\": \"Quiero una pelicula que sea similar a Star Wars\"})\n",
    "print(\"Recomendacion:\")\n",
    "print(result1[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7e6d672e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendacion:\n",
      "No encontré coincidencias precisas.\n",
      "\n",
      "Justificación: La canción \"Wonderwall\" de Oasis es una pieza musical que no tiene directamente un equivalente en los libros proporcionados, todos de temática distópica o ficción científica. Sin embargo, si buscas algo con temas profundos y narrativas complejas, te recomendaría \"El nombre del viento\", que cuenta la historia de un personaje con talentos excepcionales, similar a la emoción que puede generar una canción icónica.\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 2: Libro\n",
    "result1 = app.invoke({\"input\": \"Quiero un libro que se parezca a la cancion de Wonderwall de Oasis\"})\n",
    "print(\"Recomendacion:\")\n",
    "print(result1[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "17fdc810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendacion:\n",
      "Los tornillos son piezas metálicas con un filo helicoidal que se utilizan para fijar y unir materiales aprietándolos en otras piezas previamente agujereadas.\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 2: Libro\n",
    "result1 = app.invoke({\"input\": \"que son los tornillos?\"})\n",
    "print(\"Recomendacion:\")\n",
    "print(result1[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "642ffefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado Matemáticas:\n",
      "¡Claro! Vamos a resolver esta operación paso a paso:\n",
      "\n",
      "### Paso 1: Identificar los números a sumar\n",
      "Tenemos dos números que necesitamos sumar:\n",
      "- El primer número es **5**.\n",
      "- El segundo número es **3**.\n",
      "\n",
      "### Paso 2: Aplicar la regla de suma\n",
      "La suma se realiza al combinar o añadir estos dos valores. En este caso, estamos sumando un número entero positivo (5) y otro número entero positivo (3).\n",
      "\n",
      "### Paso 3: Realizar la operación aritmética\n",
      "Para sumar estos números, simplemente combinamos los valores:\n",
      "\\[ 5 + 3 = 8 \\]\n",
      "\n",
      "### Paso 4: Verificar el resultado\n",
      "Podemos verificar que nuestro cálculo es correcto si consideramos una representación visual o numérica. Por ejemplo, si tenemos 5 objetos y añadimos 3 más, en total tendremos 8 objetos.\n",
      "\n",
      "### Conclusion\n",
      "La suma de 5 y 3 es **8**.\n",
      "\n",
      "Entonces, la respuesta final a la pregunta \"Calcula la suma de 5 y 3\" es:\n",
      "\\[ \\boxed{8} \\]\n",
      "Herramientas usadas: []\n",
      "\n",
      "Resultado Lengua:\n",
      "Claro, voy a analizar la oración \"Quiero jugar al fútbol\" paso a paso desde el punto de vista gramatical y sintáctico.\n",
      "\n",
      "1. **Identificación del tipo de oración**: La oración es una oración simple o afirmativa, ya que contiene solo un sujeto y un predicado sin subordinaciones ni coordinaciones adicionales.\n",
      "\n",
      "2. **Identificación del sujeto**: El sujeto de la oración es \"Quiero\". En este caso, se trata de un verbo en forma personal (primera persona del singular) que funciona como sustantivo o sustituye al nombre del sujeto implícito. Es importante mencionar que en español, a veces el sujeto explícito puede ser omitido y entenderse por contexto.\n",
      "\n",
      "3. **Identificación del predicado**: El predicado es \"jugar al fútbol\". Este se divide en:\n",
      "   - **Verbo principal**: \"jugar\" (infinitivo que funciona como verbo principal).\n",
      "   - **Complemento verbal**: \"al fútbol\" (complemento directo que indica a qué se refiere el acto de jugar).\n",
      "\n",
      "4. **Análisis del complemento verbal**:\n",
      "   - **Preposición**: \"al\". En este caso, la preposición \"a\" se transforma en \"al\" por la influencia de la palabra que sigue (fútbol), que comienza con una vocal.\n",
      "   - **Nombre**: \"fútbol\". Aquí se utiliza el artículo definido \"el\" o \"al\" (en este caso, al) seguido del nombre propio \"fútbol\".\n",
      "\n",
      "5. **Análisis de la concordancia verbal y nominal**:\n",
      "   - El verbo \"jugar\" es conjugado en primera persona singular del presente de indicativo: \"Quiero\". Esto indica que el sujeto (yo) está manifestando un deseo o intención.\n",
      "   - El nombre \"fútbol\" es singular, lo cual concuerda con la forma verbal.\n",
      "\n",
      "6. **Análisis de la voz y tiempo del verbo**: El verbo \"jugar\" está en primera persona singular (yo), presente de indicativo, lo que indica una acción futura o actual pero no repetitiva.\n",
      "\n",
      "7. **Estructura sintáctica**:\n",
      "   - Sujeto: Quiero\n",
      "   - Verbo principal: jugar\n",
      "   - Complemento directo: al fútbol\n",
      "\n",
      "En resumen, la oración \"Quiero jugar al fútbol\" es una oración simple en primera persona del singular, presente de indicativo. El sujeto es implícito y el verbo principal es \"jugar\", complementado por un complemento directo \"al fútbol\".\n",
      "\n",
      "Resultado General:\n",
      "Claro, voy a explicar lo que es un tornillo y cómo funciona este elemento mecánico pasos a pasos:\n",
      "\n",
      "1. **Definición Básica**: Un tornillo es una pieza de hardware cilíndrica con una hélice o viga en su superficie externa. Su función principal es unir dos o más partes de un objeto, normalmente metálicas o plásticas, a través del intercambio de fuerzas.\n",
      "\n",
      "2. **Componentes Principales**:\n",
      "   - **Cuerpo del Tornillo**: Es la parte central cilíndrica que contiene la hélice.\n",
      "   - **Hélice (Viga)**: La superficie enroscada que se inserta en un agujero de tornillo o en una pieza receptora.\n",
      "   - **Punta del Tornillo**: La parte terminal del tornillo, generalmente más fina y afilada para facilitar su inserción.\n",
      "\n",
      "3. **Funcionamiento**:\n",
      "   - Cuando se aprieta el tornillo con un destornillador, la hélice rota en el agujero o receptáculo, desplazando las piezas unidas hacia adentro.\n",
      "   - La presión y el intercambio de fuerzas entre las superficies unidas mantienen al tornillo fijo.\n",
      "\n",
      "4. **Tipos de Tornillos**:\n",
      "   - Existen varios tipos de tornillos para diferentes aplicaciones, como los tornillos de corte (que se deslizan en una abertura preexistente), los tornillos de expansión (que crean su propio agujero al ser apretados) y los tornillos soldados (que se funden con el material del que están hechos las piezas unidas).\n",
      "\n",
      "5. **Aplicaciones**:\n",
      "   - Se utilizan en una amplia variedad de aplicaciones, desde reparaciones caseras hasta montajes industriales.\n",
      "   - Son esenciales en la construcción, electrónica, automotriz y muchas otras industrias.\n",
      "\n",
      "Espero que esta explicación detallada sea útil. ¿Hay algún aspecto más específico sobre los tornillos que te gustaría saber?\n"
     ]
    }
   ],
   "source": [
    "# Crea el grafo\n",
    "app = create_graph()\n",
    "\n",
    "# Ejemplo 1: Pregunta matemática\n",
    "result1 = app.invoke({\"input\": \"Calcula la suma de 5 y 3\"})\n",
    "print(\"Resultado Matemáticas:\")\n",
    "print(result1[\"output\"])\n",
    "print(\"Herramientas usadas:\", result1.get(\"used_tools\", []))\n",
    "\n",
    "# Ejemplo 2: Pregunta de lengua\n",
    "result2 = app.invoke({\"input\": \"Analiza esta oración gramatical, la oracion es la siguiente: Quiero jugar al futbol.\"})\n",
    "print(\"\\nResultado Lengua:\")\n",
    "print(result2[\"output\"])\n",
    "\n",
    "# Ejemplo 3: Pregunta general\n",
    "result3 = app.invoke({\"input\": \"Que es un tornillo\"})\n",
    "print(\"\\nResultado General:\")\n",
    "print(result3[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNIR_Practicas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
