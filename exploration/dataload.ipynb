{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e44e542e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'books.csv', 'row': 0}, page_content='isbn: 1909531197\\nlanguage_code: eng\\naverage_rating: 4.10\\ndescription: The story of The Boy in the Striped Pyjamasis very difficult to describe. Usually we give some clues about the book on the cover, but in this case we think that would spoil the reading of the book. We think it is important that you start to read without knowing what it is about.If you do start to read this book, you will go on a journey with a nine,year,old boy called Bruno. And sooner or later you will arrive with Bruno at a fence.We hope you never have to cross such a fence.\\nAuthors: John Boyne\\nnum_pages: 215\\npublication_year: 2014\\ntitle: The Boy in the Striped Pyjamas\\ngenre: history_biography'), Document(metadata={'source': 'books.csv', 'row': 1}, page_content=\"isbn: 9782246857\\nlanguage_code: fre\\naverage_rating: 4.39\\ndescription: En 1992, Gabriel, dix ans, vit au Burundi avec son pere francais, entrepreneur, sa mere rwandaise et sa petite soeur, Ana, dans un confortable quartier d'expatries. Gabriel passe le plus clair de son temps avec ses copains, une joyeuse bande occupee a faire les quatre cents coups. Un quotidien paisible, une enfance douce qui vont se disloquer en meme temps que ce d'Afrique brutalement malmene par l'Histoire. Gabriel voit avec inquietude ses parents se separer, puis la guerre civile se profiler, suivie du drame rwandais. Le quartier est bouleverse. Par vagues successives, la violence l'envahit, l'impregne, et tout bascule. Gabriel se croyait un enfant, il va se decouvrir metis, Tutsi, Francais...\\nAuthors: Gael Faye\\nnum_pages: 217\\npublication_year: 2016\\ntitle: Petit Pays\\ngenre: history_biography\")]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m md \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mpage_content\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Construir page_content con descripción y género juntos\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m description \u001b[38;5;241m=\u001b[39m \u001b[43mmd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m genre \u001b[38;5;241m=\u001b[39m md\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenre\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m page_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDescription: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdescription\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mGenre: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgenre\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain.schema import Document\n",
    "loader = CSVLoader(file_path=\"books.csv\",csv_args={\"delimiter\": \";\"})\n",
    "\n",
    "data = loader.load()\n",
    "print(data)\n",
    "# Aquí modificamos cada documento para separar contenido y metadatos\n",
    "new_docs = []\n",
    "for doc in data:\n",
    "    md = doc.page_content\n",
    "\n",
    "    # Construir page_content con descripción y género juntos\n",
    "    description = md.get(\"description\", \"\")\n",
    "    genre = md.get(\"genre\", \"\")\n",
    "    page_content = f\"Description: {description}\\nGenre: {genre}\"\n",
    "    # Construir metadatos excluyendo descripción y género\n",
    "    metadata = {k: v for k, v in md.items() if k not in [\"description\", \"genre\"]}\n",
    "\n",
    "    # Crear nuevo documento con content y metadatos separados\n",
    "    new_doc = Document(page_content=page_content, metadata=metadata)\n",
    "    new_docs.append(new_doc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fdeb7e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer el CSV con pandas\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"books.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "# Lista para almacenar los Document\n",
    "documents = []\n",
    "for index, row in df.iterrows():\n",
    "    # Extraer los campos que van al contenido (embedding)\n",
    "    description = str(row.get(\"description\", \"\"))\n",
    "    genre = str(row.get(\"genre\", \"\"))\n",
    "    page_content = f\"Description: {description}\\nGenre: {genre}\"\n",
    "    # Construir metadata con el resto de columnas\n",
    "    metadata = {\n",
    "        \"isbn\": row.get(\"isbn\"),\n",
    "        \"language_code\": row.get(\"language_code\"),\n",
    "        \"average_rating\": row.get(\"average_rating\"),\n",
    "        \"Authors\": row.get(\"Authors\"),\n",
    "        \"num_pages\": row.get(\"num_pages\"),\n",
    "        \"publication_year\": row.get(\"publication_year\"),\n",
    "        \"title\": row.get(\"title\")\n",
    "    }\n",
    "    doc = Document(page_content=page_content, metadata=metadata)\n",
    "    documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46c0ed6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from pymilvus import CollectionSchema, FieldSchema, DataType, Collection\n",
    "from pymilvus import connections, utility\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb700b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palom\\AppData\\Local\\Temp\\ipykernel_9488\\778662523.py:30: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embeddings = OllamaEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "    df = pd.read_csv(\"books.csv\", sep=\";\", encoding=\"utf-8\")\n",
    "    from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "    # Lista para almacenar los Document\n",
    "    documents = []\n",
    "    for index, row in df.iterrows():\n",
    "        # Extraer los campos que van al contenido (embedding)\n",
    "        description = str(row.get(\"description\", \"\"))\n",
    "        genre = str(row.get(\"genre\", \"\"))\n",
    "        page_content = f\"Description: {description}\\nGenre: {genre}\"\n",
    "        # Construir metadata con el resto de columnas\n",
    "        metadata = {\n",
    "            \"isbn\": row.get(\"isbn\"),\n",
    "            \"language_code\": row.get(\"language_code\"),\n",
    "            \"average_rating\": row.get(\"average_rating\"),\n",
    "            \"Authors\": row.get(\"Authors\"),\n",
    "            \"num_pages\": row.get(\"num_pages\"),\n",
    "            \"publication_year\": row.get(\"publication_year\"),\n",
    "            \"title\": row.get(\"title\")\n",
    "        }\n",
    "        doc = Document(page_content=page_content, metadata=metadata)\n",
    "        documents.append(doc)\n",
    "\n",
    "    # Dividir los documentos\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "                chunk_size=1000,\n",
    "                chunk_overlap=200\n",
    "            )\n",
    "    splits = text_splitter.split_documents(documents)\n",
    "    # Crear embeddings y vectorstore\n",
    "    embeddings = OllamaEmbeddings(\n",
    "        model=\"qwen2.5\",\n",
    "        base_url=\"http://localhost:11434\"\n",
    "    )\n",
    "    vector = FAISS.from_documents(splits, embeddings)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0c8745c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    from langchain.embeddings import HuggingFaceEmbeddings\n",
    "    HOST = \"localhost\"\n",
    "    PORT = \"19530\"\n",
    "    connections.connect(host=HOST, port=PORT)\n",
    "    COLLECTION_NAME=\"Pruebas\"\n",
    "# Extrae los embeddings y documentos de tu FAISS\n",
    "    vectors = vector.index.reconstruct_n(0, vector.index.ntotal)  # Obtiene todos los vectores\n",
    "    documents = [doc.page_content for doc in splits]       # Tus textos originales\n",
    "    metadatas = [doc.metadata for doc in splits]           # Metadatos asociados\n",
    "\n",
    "    # Crea la colección en Milvus (si no existe)\n",
    "    if not utility.has_collection(COLLECTION_NAME):\n",
    "        dim = len(vectors[0])  # Dimensión de tus embeddings (ej: 384, 768, etc.)\n",
    "        \n",
    "        fields = [\n",
    "            FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "            FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=dim),\n",
    "            FieldSchema(name=\"text\", dtype=DataType.VARCHAR, max_length=65535),\n",
    "            FieldSchema(name=\"metadata\", dtype=DataType.JSON)\n",
    "        ]\n",
    "        schema = CollectionSchema(fields, description=\"Índice de embeddings\")\n",
    "        collection = Collection(name=COLLECTION_NAME, schema=schema)\n",
    "        \n",
    "        # Crea un índice HNSW para búsquedas eficientes\n",
    "        index_params = {\n",
    "            \"metric_type\": \"L2\",  # Distancia euclidiana (usa \"IP\" para producto interno)\n",
    "            \"index_type\": \"HNSW\",\n",
    "            \"params\": {\"M\": 16, \"efConstruction\": 200}\n",
    "        }\n",
    "        collection.create_index(field_name=\"embedding\", index_params=index_params)\n",
    "\n",
    "    # Guarda los datos en Milvus\n",
    "    data = [\n",
    "        vectors,                    # Embeddings\n",
    "        documents,                  # Textos originales\n",
    "        metadatas                   # Metadatos (opcional)\n",
    "    ]\n",
    "\n",
    "    # Inserta los datos\n",
    "    collection = Collection(COLLECTION_NAME)\n",
    "    collection.insert(data)\n",
    "    collection.flush()\n",
    "    collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a242e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colecciones existentes: ['Pruebas']\n"
     ]
    }
   ],
   "source": [
    "print(\"Colecciones existentes:\", utility.list_collections())\n",
    "collection.flush()\n",
    "collection.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acae339c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Campos: [{'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': True}, {'name': 'embedding', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 3584}}, {'name': 'text', 'description': '', 'type': <DataType.VARCHAR: 21>, 'params': {'max_length': 65535}}, {'name': 'metadata', 'description': '', 'type': <DataType.JSON: 23>}]\n"
     ]
    }
   ],
   "source": [
    "print(\"Campos:\", collection.schema.fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ddd031d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metadata': {'isbn': 1909531197, 'language_code': 'eng', 'average_rating': 4.1, 'Authors': 'John Boyne', 'num_pages': 215, 'publication_year': 2014, 'title': 'The Boy in the Striped Pyjamas'}, 'id': 458622025556822550, 'text': 'Description: The story of The Boy in the Striped Pyjamasis very difficult to describe. Usually we give some clues about the book on the cover, but in this case we think that would spoil the reading of the book. We think it is important that you start to read without knowing what it is about.If you do start to read this book, you will go on a journey with a nine,year,old boy called Bruno. And sooner or later you will arrive with Bruno at a fence.We hope you never have to cross such a fence.\\nGenre: history_biography'}\n",
      "{'metadata': {'isbn': 9782246857, 'language_code': 'fre', 'average_rating': 4.39, 'Authors': 'Gael Faye', 'num_pages': 217, 'publication_year': 2016, 'title': 'Petit Pays'}, 'id': 458622025556822551, 'text': \"Description: En 1992, Gabriel, dix ans, vit au Burundi avec son pere francais, entrepreneur, sa mere rwandaise et sa petite soeur, Ana, dans un confortable quartier d'expatries. Gabriel passe le plus clair de son temps avec ses copains, une joyeuse bande occupee a faire les quatre cents coups. Un quotidien paisible, une enfance douce qui vont se disloquer en meme temps que ce d'Afrique brutalement malmene par l'Histoire. Gabriel voit avec inquietude ses parents se separer, puis la guerre civile se profiler, suivie du drame rwandais. Le quartier est bouleverse. Par vagues successives, la violence l'envahit, l'impregne, et tout bascule. Gabriel se croyait un enfant, il va se decouvrir metis, Tutsi, Francais...\\nGenre: history_biography\"}\n",
      "{'metadata': {'isbn': 1909531197, 'language_code': 'eng', 'average_rating': 4.1, 'Authors': 'John Boyne', 'num_pages': 215, 'publication_year': 2014, 'title': 'The Boy in the Striped Pyjamas'}, 'id': 458622025556822553, 'text': 'Description: The story of The Boy in the Striped Pyjamasis very difficult to describe. Usually we give some clues about the book on the cover, but in this case we think that would spoil the reading of the book. We think it is important that you start to read without knowing what it is about.If you do start to read this book, you will go on a journey with a nine,year,old boy called Bruno. And sooner or later you will arrive with Bruno at a fence.We hope you never have to cross such a fence.\\nGenre: history_biography'}\n",
      "{'metadata': {'isbn': 9782246857, 'language_code': 'fre', 'average_rating': 4.39, 'Authors': 'Gael Faye', 'num_pages': 217, 'publication_year': 2016, 'title': 'Petit Pays'}, 'id': 458622025556822554, 'text': \"Description: En 1992, Gabriel, dix ans, vit au Burundi avec son pere francais, entrepreneur, sa mere rwandaise et sa petite soeur, Ana, dans un confortable quartier d'expatries. Gabriel passe le plus clair de son temps avec ses copains, une joyeuse bande occupee a faire les quatre cents coups. Un quotidien paisible, une enfance douce qui vont se disloquer en meme temps que ce d'Afrique brutalement malmene par l'Histoire. Gabriel voit avec inquietude ses parents se separer, puis la guerre civile se profiler, suivie du drame rwandais. Le quartier est bouleverse. Par vagues successives, la violence l'envahit, l'impregne, et tout bascule. Gabriel se croyait un enfant, il va se decouvrir metis, Tutsi, Francais...\\nGenre: history_biography\"}\n"
     ]
    }
   ],
   "source": [
    "collection.load()\n",
    "results = collection.query(\n",
    "    expr=\"\",  # Sin filtro\n",
    "    output_fields=[\"text\", \"metadata\"],\n",
    "    limit=5\n",
    ")\n",
    "for r in results:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810a2947",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Milvus.__init__() got an unexpected keyword argument 'embedding_field'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HuggingFaceEmbeddings\n\u001b[0;32m      3\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \n\u001b[1;32m----> 4\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m \u001b[43mMilvus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcollection_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPruebas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43membedding_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43membeddings\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtext_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconnection_args\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocalhost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mport\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m19530\u001b[39;49m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[43m                \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m docs \u001b[38;5;241m=\u001b[39m vectorstore\u001b[38;5;241m.\u001b[39msimilarity_search(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscience fiction book about artificial intelligence\u001b[39m\u001b[38;5;124m\"\u001b[39m, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(docs)\n",
      "File \u001b[1;32mc:\\Users\\palom\\.conda\\envs\\UNIR_Practicas\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:224\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    223\u001b[0m     emit_warning()\n\u001b[1;32m--> 224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mTypeError\u001b[0m: Milvus.__init__() got an unexpected keyword argument 'embedding_field'"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Milvus\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")   \n",
    "vectorstore = Milvus(\n",
    "            collection_name=\"Pruebas\",\n",
    "            embedding_function=embeddings,\n",
    "            vector_field=\"embeddings\",\n",
    "            text_field=\"text\",\n",
    "            connection_args={\n",
    "                \"host\": \"localhost\",\n",
    "                \"port\": 19530\n",
    "\n",
    "                \n",
    "            }\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "docs = vectorstore.similarity_search(\"science fiction book about artificial intelligence\", k=1)\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8e1b59f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\palom\\AppData\\Local\\Temp\\ipykernel_19348\\2122410605.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "c:\\Users\\palom\\.conda\\envs\\UNIR_Practicas\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'HuggingFaceEmbeddings' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m HuggingFaceEmbeddings(model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscience fiction book about artificial intelligence\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 4\u001b[0m query_vector \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m(query)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Lanza la búsqueda en Milvus\u001b[39;00m\n\u001b[0;32m      7\u001b[0m results \u001b[38;5;241m=\u001b[39m collection\u001b[38;5;241m.\u001b[39msearch(\n\u001b[0;32m      8\u001b[0m     data\u001b[38;5;241m=\u001b[39m[query_vector],            \u001b[38;5;66;03m# lista de vectores a buscar\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     anns_field\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m\"\u001b[39m,         \u001b[38;5;66;03m# nombre del campo con los vectores\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     12\u001b[0m     output_fields\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     13\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\palom\\.conda\\envs\\UNIR_Practicas\\lib\\site-packages\\pydantic\\main.py:994\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    991\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[0;32m    992\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    993\u001b[0m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[1;32m--> 994\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HuggingFaceEmbeddings' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "# Frase de consulta\n",
    "model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "query = \"science fiction book about artificial intelligence\"\n",
    "query_vector = model.encode(query).tolist()\n",
    "\n",
    "# Lanza la búsqueda en Milvus\n",
    "results = collection.search(\n",
    "    data=[query_vector],            # lista de vectores a buscar\n",
    "    anns_field=\"embedding\",         # nombre del campo con los vectores\n",
    "    param={\"metric_type\": \"L2\", \"params\": {\"ef\": 128}},\n",
    "    limit=5,\n",
    "    output_fields=[\"text\", \"metadata\"]\n",
    ")\n",
    "\n",
    "# Muestra resultados\n",
    "for hits in results:\n",
    "    for hit in hits:\n",
    "        print(\"Score:\", hit.distance)\n",
    "        print(\"Texto:\", hit.entity.get(\"text\"))\n",
    "        print(\"Metadata:\", hit.entity.get(\"metadata\"))\n",
    "        print(\"-\" * 40)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UNIR_Practicas",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
